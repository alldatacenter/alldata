[{
  "id": 87,
  "gmtCreate": 1646306448266,
  "gmtModified": 1646306448266,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_pod_event_collect",
  "alias": "POD事件明细采集作业(内置)",
  "tags": ["pod", "event", "oem"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "10 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 84,
      "gmtCreate": 1646306448259,
      "gmtModified": 1646306448259,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_pod_event",
      "alias": "POD事件明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport time\nimport requests\n\nheaders = {}\n\npage_size = 1000\none_millisecond = 1000\none_minutes_millisecond = 60000\n\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\n\ndef get_time_range(ts, delta_ts, forward_gap=0):\n    \"\"\"\n    时间范围\n    :param ts:\n    :param delta_ts:\n    :param forward_gap: 默认前推一个delta\n    :return:\n    \"\"\"\n    ts_integer = int(ts)\n    delta_ts_integer = int(delta_ts)\n\n    end_ts = ts_integer - ts_integer % delta_ts_integer\n    start_ts = end_ts - delta_ts_integer\n\n    delta_forward_ts_integer = delta_ts_integer * forward_gap\n\n    return start_ts - delta_forward_ts_integer, end_ts - delta_forward_ts_integer\n\n\ndef get_pod_events():\n    endpoint = host[\"dataset\"] + \"/interface/kubernetes_event\"\n    start_timestamp, end_timestamp = get_time_range(time.time() * one_millisecond, one_minutes_millisecond)\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&kind=Pod'''\n\n    page_num = 1\n    events = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                events.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n\n    uid_set = set([])\n    de_duplicate_events = []\n    for event in events:\n        uid = event.get('uid')\n        if uid not in uid_set:\n            uid_set.add(uid)\n            event[\"id\"] = uid\n            event[\"podName\"] = event[\"name\"]\n            event[\"timestamp\"] = int(time.time() * one_millisecond)\n            de_duplicate_events.append(event)\n    return de_duplicate_events\n\n\nprint(json.dumps(get_pod_events()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 116,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 88,
  "gmtCreate": 1646306448345,
  "gmtModified": 1646381024765,
  "creator": "",
  "operator": "999999999",
  "appId": "",
  "name": "oem_app_delivery_deployment_collect",
  "alias": "应用构建部署明细采集作业(内置)",
  "tags": ["delivery", "deployment"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 1 * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 85,
      "gmtCreate": 1646306448334,
      "gmtModified": 1646306448334,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_delivery",
      "alias": "应用交付构建明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport time\n\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef convert_utc_to_local_dt(str_utc_time):\n    # return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc).astimezone(tz.tzlocal())\n    return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc) \\\n        .astimezone(datetime.timezone(datetime.timedelta(hours=8)))\n\n\ndef _do_get_sreworks_action(action_label):\n    # now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    # now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    start_ds = now_utc_dt.strftime(\"%Y%m%d\")\n    now_timestamp = int(time.time()) * one_second_millisecond\n    end_timestamp = now_timestamp - now_timestamp % one_hour_millisecond\n    start_timestamp = end_timestamp - one_hour_millisecond\n\n    query = f\"start_time:[{start_timestamp} TO {end_timestamp}] AND action_label:{action_label}\"\n    basic_url = host[\"dataset\"] + f'''/interface/action?query={query}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas, start_ds\n\n\ndef get_sreworks_action():\n    actions, start_ds = _do_get_sreworks_action(\"应用构建\")\n    deliveries = []\n    for action in actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        if \"appId\" in params and \"teamId\" in params:\n            delivery = {\n                \"id\": exec_data[\"data\"][\"appPackageTaskId\"],\n                \"appId\": params[\"appId\"],\n                \"teamId\": params[\"teamId\"],\n                \"version\": params[\"build_version\"],\n                \"status\": exec_data[\"status\"],\n                \"startTime\": action[\"start_time\"],\n                \"endTime\": action[\"end_time\"],\n                \"ds\": start_ds\n            }\n            deliveries.append(delivery)\n\n    return deliveries\n\n\nprint(json.dumps(get_sreworks_action()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 112,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 86,
      "gmtCreate": 1646306448340,
      "gmtModified": 1646306448340,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_deployment",
      "alias": "应用部署明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = {}\n    if datas:\n        for data in datas[\"items\"]:\n            app_instances[data[\"appInstanceName\"]] = data[\"appInstanceId\"]\n    return app_instances\n\n\ndef _do_get_sreworks_action(action_label):\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    start_ds = now_utc_dt.strftime(\"%Y%m%d\")\n    now_timestamp = int(time.time()) * one_second_millisecond\n    end_timestamp = now_timestamp - now_timestamp % one_hour_millisecond\n    start_timestamp = end_timestamp - one_hour_millisecond\n\n    query = f\"start_time:[{start_timestamp} TO {end_timestamp}] AND action_label:{action_label}\"\n    basic_url = host[\"dataset\"] + f'''/interface/action?query={query}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas, start_ds\n\n\ndef get_sreworks_action():\n    actions, start_ds = _do_get_sreworks_action(\"应用部署\")\n    app_instance_dict = get_app_instances()\n    deployments = []\n    for action in actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        app_instance_name = params.get(\"appInstanceName\", None)\n        if app_instance_name in app_instance_dict:\n            deployment = {\n                \"id\": exec_data[\"data\"][\"deployAppId\"],\n                \"appId\": params[\"appId\"],\n                \"appInstanceId\": app_instance_dict[app_instance_name],\n                \"appInstanceName\": app_instance_name,\n                \"appName\": params[\"appName\"],\n                \"clusterId\": params[\"clusterId\"],\n                \"namespace\": params[\"namespaceId\"],\n                \"teamId\": params[\"teamId\"],\n                \"version\": params[\"simplePackageVersion\"],\n                \"status\": exec_data[\"status\"],\n                \"startTime\": action[\"start_time\"],\n                \"endTime\": action[\"end_time\"],\n                \"ds\": start_ds\n            }\n            deployments.append(deployment)\n\n    return deployments\n\n\nprint(json.dumps(get_sreworks_action()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 113,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 89,
  "gmtCreate": 1646306448396,
  "gmtModified": 1646306448396,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_delivery_deployment_stats_collect",
  "alias": "应用构建部署统计采集作业(内置)",
  "tags": ["delivery", "deployment", "stats"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 0 1 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 87,
      "gmtCreate": 1646306448381,
      "gmtModified": 1646306448381,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_delivery_deployment_quality",
      "alias": "应用构建部署质量统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = {}\n    if datas:\n        for data in datas[\"items\"]:\n            app_instances[data[\"appInstanceName\"]] = data[\"appInstanceId\"]\n    return app_instances\n\n\ndef _do_get_sreworks_action(action_label):\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    query = f\"start_time:[{start_timestamp} TO {end_timestamp}] AND action_label:{action_label}\"\n    basic_url = host[\"dataset\"] + f'''/interface/action?query={query}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas, start_ds, start_timestamp\n\n\ndef get_sreworks_action():\n    delivery_actions, start_ds, start_timestamp = _do_get_sreworks_action(\"应用构建\")\n    deployment_actions, start_ds, start_timestamp = _do_get_sreworks_action(\"应用部署\")\n    app_instance_dict = get_app_instances()\n\n    deliveries = {}\n    for action in delivery_actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        if \"appId\" in params and \"teamId\" in params:\n            app_id = params[\"appId\"]\n            if app_id in deliveries:\n                delivery = deliveries[app_id]\n                delivery[\"cnt\"] += 1\n                delivery[\"successCnt\"] = delivery[\"successCnt\"] + 1 if exec_data[\"status\"] == \"SUCCESS\" else delivery[\"successCnt\"]\n                delivery[\"successRate\"] = delivery[\"successCnt\"] / delivery[\"cnt\"]\n            else:\n                success_cnt = 1 if exec_data[\"status\"] == \"SUCCESS\" else 0\n                delivery = {\n                    \"appId\": params[\"appId\"],\n                    \"teamId\": params[\"teamId\"],\n                    \"cnt\": 1,\n                    \"successCnt\": success_cnt,\n                    \"successRate\": success_cnt / 1\n                }\n                deliveries[app_id] = delivery\n\n    deployments = {}\n    for action in deployment_actions:\n        exec_data = action[\"exec_data\"]\n        params = action[\"action_meta_data\"].get(\"params\", {})\n        app_instance_name = params.get(\"appInstanceName\", None)\n        if app_instance_name in app_instance_dict:\n            app_instance_id = app_instance_dict[app_instance_name]\n            if app_instance_id in deployments:\n                deployment = deployments[app_instance_id]\n                deployment[\"cnt\"] += 1\n                deployment[\"successCnt\"] = deployment[\"successCnt\"] + 1 if exec_data[\"status\"] == \"SUCCESS\" else deployment[\"successCnt\"]\n                deployment[\"successRate\"] = deployment[\"successCnt\"] / deployment[\"cnt\"]\n            else:\n                success_cnt = 1 if exec_data[\"status\"] == \"SUCCESS\" else 0\n                deployment = {\n                    \"appId\": params[\"appId\"],\n                    \"appInstanceId\": app_instance_id,\n                    \"appInstanceName\": app_instance_name,\n                    \"appName\": params[\"appName\"],\n                    \"teamId\": params[\"teamId\"],\n                    \"cnt\": 1,\n                    \"successCnt\": success_cnt,\n                    \"successRate\": success_cnt / 1\n                }\n                deployments[app_instance_id] = deployment\n\n    qualities = []\n    for deployment in list(deployments.values()):\n        app_id = deployment[\"appId\"]\n        delivery = deliveries[app_id]\n        quality = {\n            \"id\": deployment[\"appInstanceId\"],\n            \"ds\": start_ds,\n            \"appId\": deployment[\"appId\"],\n            \"appInstanceId\": deployment[\"appInstanceId\"],\n            \"appInstanceName\": deployment[\"appInstanceName\"],\n            \"teamId\": deployment[\"teamId\"],\n            \"deliveryCntDailyAdditions\": delivery[\"cnt\"],\n            \"deliverySuccessCntDailyAdditions\": delivery[\"successCnt\"],\n            \"deliverySuccessRateDaily\": delivery[\"successRate\"],\n            \"deploymentCntDailyAdditions\": deployment[\"cnt\"],\n            \"deploymentSuccessCntDailyAdditions\": deployment[\"successCnt\"],\n            \"deploymentSuccessRateDaily\": deployment[\"successRate\"],\n            \"timestamp\": start_timestamp\n        }\n        qualities.append(quality)\n\n    return qualities\n\n\nprint(json.dumps(get_sreworks_action()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 114,
        "type": "model",
        "layer": "ads"
      }
    }, {
      "id": 88,
      "gmtCreate": 1646306448391,
      "gmtModified": 1646306448391,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_delivery_deployment_efficiency",
      "alias": "应用构建部署效率统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n}\n\naccount_super_client_id = \"common\"\naccount_super_id = \"admin\"\naccount_super_client_secret = \"common-9efab2399c7c560b34de477b9aa0a465\"\naccount_super_secret_key = \"test-super-secret-key\"\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef _do_query_dataset_interface(basic_url):\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas\n\n\ndef get_dd_efficiency():\n    team_user_url = host[\"dataset\"] + f'''/interface/team_user?pageSize={page_size}'''\n    team_users = _do_query_dataset_interface(team_user_url)\n\n    team_user_cnt = {}\n    for team_user in team_users:\n        team_id = team_user[\"teamId\"]\n        if team_id in team_user_cnt:\n            team_user_cnt[team_id] += 1\n        else:\n            team_user_cnt[team_id] = 1\n\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    dd_quality_url = host[\"dataset\"] + f'''/interface/app_delivery_deployment_quality?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    dd_qualities = _do_query_dataset_interface(dd_quality_url)\n\n    efficiencies = []\n    for quality in dd_qualities:\n        team_id = quality[\"teamId\"]\n        team_member_cnt = team_user_cnt[team_id]\n        efficiency = {\n            \"id\": quality[\"appInstanceId\"],\n            \"ds\": start_ds,\n            \"appId\": quality[\"appId\"],\n            \"appInstanceId\": quality[\"appInstanceId\"],\n            \"appInstanceName\": quality[\"appInstanceName\"],\n            \"teamId\": team_id,\n            \"teamMemberCnt\": team_member_cnt,\n            \"deliveryCntDailyAdditions\": quality[\"deliveryCntDailyAdditions\"],\n            \"deploymentCntDailyAdditions\": quality[\"deploymentCntDailyAdditions\"],\n            \"hrEffectivenessRatioDaily\": (quality[\"deploymentCntDailyAdditions\"] + quality[\"deliveryCntDailyAdditions\"]) / team_member_cnt,\n            \"timestamp\": start_timestamp\n        }\n        efficiencies.append(efficiency)\n    return efficiencies\n\n\nprint(json.dumps(get_dd_efficiency()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 115,
        "type": "model",
        "layer": "ads"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 90,
  "gmtCreate": 1646306448458,
  "gmtModified": 1646306448458,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_resource_allocated_cost_stats_collect",
  "alias": "应用资源分配成本统计采集作业(内置)",
  "tags": ["app", "resource", "cost", "stats"],
  "description": "应用资源分配成本统计采集作业(内置)",
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 30 0 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 89,
      "gmtCreate": 1646306448434,
      "gmtModified": 1646306448434,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_cluster_resource_price",
      "alias": "集群计费维度数据(内置)",
      "execTimeout": 30,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\n\n\ndef get_default_resource_price():\n    prices = [\n        {\n            \"id\": \"default\",\n            \"clusterId\": \"default\",\n            \"monthlyCpuPrice\": 109.5,\n            \"monthlyRamPrice\": 36.50,\n            \"monthlyStoragePrice\": 18.25,\n            \"currency\": \"CNY\"\n        },\n        {\n            \"id\": \"21id\",\n            \"clusterId\": \"21id\",\n            \"monthlyCpuPrice\": 109.5,\n            \"monthlyRamPrice\": 36.50,\n            \"monthlyStoragePrice\": 18.25,\n            \"currency\": \"CNY\"\n        },\n        {\n            \"id\": \"12id\",\n            \"clusterId\": \"12id\",\n            \"monthlyCpuPrice\": 109.5,\n            \"monthlyRamPrice\": 36.50,\n            \"monthlyStoragePrice\": 18.25,\n            \"currency\": \"CNY\"\n        }\n    ]\n\n    return prices\n\n\nprint(json.dumps(get_default_resource_price()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 110,
        "type": "model",
        "layer": "dim"
      }
    }, {
      "id": 90,
      "gmtCreate": 1646306448440,
      "gmtModified": 1646306448440,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_pod_resource_allocated_1d",
      "alias": "应用POD天级别资源分配(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef _do_get_pod_resource_allocated(endpoint, start_timestamp, end_timestamp):\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas\n\n\ndef get_pod_resource_allocated():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    endpoint_cpu_core = host[\"dataset\"] + \"/interface/pod_resource_hours_allocation\"\n    pod_resource_allocation_list = _do_get_pod_resource_allocated(endpoint_cpu_core, start_timestamp, end_timestamp)\n\n    result = {}\n    for pod_resource_allocation in pod_resource_allocation_list:\n        namespace = pod_resource_allocation[\"namespace\"]\n        pod_name = pod_resource_allocation[\"podName\"]\n        key = namespace + \"#\" + pod_name\n\n        pod_ram_gb_hours_allocation = 0 if pod_resource_allocation[\"podRamGbHoursAllocation\"] is None else pod_resource_allocation[\"podRamGbHoursAllocation\"]\n        pod_cpu_core_hours_allocation = 0 if pod_resource_allocation[\"podCpuCoreHoursAllocation\"] is None else pod_resource_allocation[\"podCpuCoreHoursAllocation\"]\n        pod_pvc_gb_hours_allocation = 0 if pod_resource_allocation[\"podPVCGbHoursAllocation\"] is None else pod_resource_allocation[\"podPVCGbHoursAllocation\"]\n        pod_cpu_core_hours_usage_avg = 0 if pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"] is None else pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"]\n        pod_ram_gb_hours_usage_avg = 0 if pod_resource_allocation[\"podRamGbHoursUsageAvg\"] is None else pod_resource_allocation[\"podRamGbHoursUsageAvg\"]\n        if key in result:\n            result[key][\"podRamGbAllocation\"] += pod_ram_gb_hours_allocation\n            result[key][\"podCpuCoreAllocation\"] += pod_cpu_core_hours_allocation\n            result[key][\"podPVCGbAllocation\"] += pod_pvc_gb_hours_allocation\n            result[key][\"podCpuCoreUsageAvg\"] += pod_cpu_core_hours_usage_avg\n            result[key][\"podRamGbUsageAvg\"] += pod_ram_gb_hours_usage_avg\n            result[key][\"ramEfficiency\"] = 1.0 if result[key][\"podRamGbAllocation\"] == 0 or result[key][\"podRamGbUsageAvg\"]>= result[key][\"podRamGbAllocation\"] else result[key][\"podRamGbUsageAvg\"] / result[key][\"podRamGbAllocation\"]\n            result[key][\"cpuEfficiency\"] = 1.0 if result[key][\"podCpuCoreAllocation\"] == 0 or result[key][\"podCpuCoreUsageAvg\"] >= result[key][\"podCpuCoreAllocation\"] else result[key][\"podCpuCoreUsageAvg\"] / result[key][\"podCpuCoreAllocation\"]\n        else:\n            result[key] = {\n                \"appInstanceId\": pod_resource_allocation[\"appInstanceId\"],\n                \"appComponentInstanceId\": pod_resource_allocation[\"appComponentInstanceId\"],\n                \"appId\": pod_resource_allocation[\"appId\"],\n                \"namespace\": pod_resource_allocation[\"namespace\"],\n                \"appComponentName\": pod_resource_allocation[\"appComponentName\"],\n                \"podName\": pod_resource_allocation[\"podName\"],\n                \"clusterId\": pod_resource_allocation[\"clusterId\"],\n                \"appInstanceName\": pod_resource_allocation[\"appInstanceName\"],\n                \"podRamGbAllocation\": pod_ram_gb_hours_allocation,\n                \"podCpuCoreAllocation\": pod_cpu_core_hours_allocation,\n                \"podPVCGbAllocation\": pod_pvc_gb_hours_allocation,\n                \"podCpuCoreUsageAvg\": pod_cpu_core_hours_usage_avg,\n                \"podRamGbUsageAvg\": pod_ram_gb_hours_usage_avg,\n                \"ramEfficiency\": 1.0 if pod_ram_gb_hours_allocation == 0 or pod_ram_gb_hours_usage_avg >= pod_ram_gb_hours_allocation else pod_ram_gb_hours_usage_avg/pod_ram_gb_hours_allocation,\n                \"cpuEfficiency\": 1.0 if pod_cpu_core_hours_allocation == 0 or pod_cpu_core_hours_usage_avg >= pod_cpu_core_hours_allocation else pod_cpu_core_hours_usage_avg/pod_cpu_core_hours_allocation,\n                \"ds\": start_ds,\n                \"id\": key,\n                \"timestamp\": start_timestamp\n            }\n    return list(result.values())\n\n\nprint(json.dumps(get_pod_resource_allocated()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 92,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 91,
      "gmtCreate": 1646306448448,
      "gmtModified": 1646306448448,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_resource_allocated_cost_1d",
      "alias": "应用天级别资源分配成本(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nmonthly_hours = 730\n\n\ndef _get_data_by_interface(basic_url):\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas\n\n\ndef get_pod_resource_allocated():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    endpoint_pod_resource = host[\"dataset\"] + \"/interface/pod_resource_allocation_stats\"\n    basic_url = f'''{endpoint_pod_resource}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    pod_resource_allocation_list = _get_data_by_interface(basic_url)\n\n    endpoint_resource_price = host[\"dataset\"] + \"/interface/resource_price\"\n    basic_url = f'''{endpoint_resource_price}?pageSize={page_size}'''\n    resource_price_list = _get_data_by_interface(basic_url)\n\n    cluster_price = {}\n    for resource_price in resource_price_list:\n        cluster_id = resource_price.get(\"clusterId\", \"default\")\n        cluster_price[cluster_id] = resource_price\n\n    app_resource_allocation = {}\n    for pod_resource_allocation in pod_resource_allocation_list:\n        cluster_id = pod_resource_allocation[\"clusterId\"]\n        if cluster_id not in cluster_price:\n            cluster_id = \"default\"\n        resource_price = cluster_price[cluster_id]\n\n        cpu_cost = (resource_price[\"monthlyCpuPrice\"]/730) * pod_resource_allocation[\"podCpuCoreAllocation\"]\n        ram_cost = (resource_price[\"monthlyRamPrice\"]/730) * pod_resource_allocation[\"podRamGbAllocation\"]\n        pvc_cost = (resource_price[\"monthlyStoragePrice\"]/730) * pod_resource_allocation[\"podPVCGbAllocation\"]\n\n        app_instance_id = pod_resource_allocation[\"appInstanceId\"]\n        if app_instance_id in pod_resource_allocation:\n            res = app_resource_allocation[app_instance_id]\n            res[\"cpuCoreAllocation\"] += pod_resource_allocation[\"podCpuCoreAllocation\"]\n            res[\"ramGbAllocation\"] += pod_resource_allocation[\"podRamGbAllocation\"]\n            res[\"pvcGbAllocation\"] += pod_resource_allocation[\"podPVCGbAllocation\"]\n            res[\"cpuCoreUsageAvg\"] += pod_resource_allocation[\"podCpuCoreUsageAvg\"]\n            res[\"ramGbUsageAvg\"] += pod_resource_allocation[\"podRamGbUsageAvg\"]\n            res[\"ramEfficiency\"] = 1.0 if res[\"ramGbAllocation\"] == 0 or res[\"ramGbUsageAvg\"] >= res[\"ramGbAllocation\"] else res[\"ramGbUsageAvg\"] / res[\"ramGbAllocation\"]\n            res[\"cpuEfficiency\"] = 1.0 if res[\"cpuCoreAllocation\"] == 0 or res[\"cpuCoreUsageAvg\"] >= res[\"cpuCoreAllocation\"] else res[\"cpuCoreUsageAvg\"] / res[\"cpuCoreAllocation\"]\n\n            res[\"cpuCost\"] += cpu_cost\n            res[\"ramCost\"] += ram_cost\n            res[\"pvcCost\"] += pvc_cost\n            res[\"cost\"] += cpu_cost + ram_cost + pvc_cost\n            res[\"podCnt\"] += 1\n        else:\n            app_resource_allocation[app_instance_id] = {\n                \"appId\": pod_resource_allocation[\"appId\"],\n                \"appInstanceId\": pod_resource_allocation[\"appInstanceId\"],\n                \"cpuCoreAllocation\": pod_resource_allocation[\"podCpuCoreAllocation\"],\n                \"ramGbAllocation\": pod_resource_allocation[\"podRamGbAllocation\"],\n                \"pvcGbAllocation\": pod_resource_allocation[\"podPVCGbAllocation\"],\n                \"cpuCoreUsageAvg\": pod_resource_allocation[\"podCpuCoreUsageAvg\"],\n                \"ramGbUsageAvg\": pod_resource_allocation[\"podRamGbUsageAvg\"],\n                \"ramEfficiency\": 1.0 if pod_resource_allocation[\"podRamGbAllocation\"] == 0 or pod_resource_allocation[\"podRamGbUsageAvg\"] >= pod_resource_allocation[\"podRamGbAllocation\"] else pod_resource_allocation[\"podRamGbUsageAvg\"]/pod_resource_allocation[\"podRamGbAllocation\"],\n                \"cpuEfficiency\": 1.0 if pod_resource_allocation[\"podCpuCoreAllocation\"] == 0 or pod_resource_allocation[\"podCpuCoreUsageAvg\"] >= pod_resource_allocation[\"podCpuCoreAllocation\"] else pod_resource_allocation[\"podCpuCoreUsageAvg\"]/pod_resource_allocation[\"podCpuCoreAllocation\"],\n                \"ds\": start_ds,\n                \"id\": pod_resource_allocation[\"appInstanceId\"],\n                \"cpuCost\": cpu_cost,\n                \"ramCost\": ram_cost,\n                \"pvcCost\": pvc_cost,\n                \"cost\": cpu_cost + ram_cost + pvc_cost,\n                \"timestamp\": start_timestamp,\n                \"currency\": resource_price[\"currency\"],\n                \"podCnt\": 1\n            }\n\n    return list(app_resource_allocation.values())\n\n\nprint(json.dumps(get_pod_resource_allocated()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 111,
        "type": "model",
        "layer": "ads"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 91,
  "gmtCreate": 1646306448535,
  "gmtModified": 1646306448535,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_health_stats_collect",
  "alias": "应用健康统计采集作业(内置)",
  "tags": ["app", "health", "stats"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 2 0 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 92,
      "gmtCreate": 1646306448500,
      "gmtModified": 1646306448500,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_risk_stats_1d",
      "alias": "应用天级别风险统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"risk\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result[\"appComponentName\"],\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 88,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 93,
      "gmtCreate": 1646306448509,
      "gmtModified": 1646306448509,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_alert_stats_1d",
      "alias": "应用天级别告警统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"alert\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result[\"appComponentName\"],\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 89,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 94,
      "gmtCreate": 1646306448514,
      "gmtModified": 1646306448514,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_incident_stats_1d",
      "alias": "应用天级别异常统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"incident\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result[\"appComponentName\"],\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 90,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 95,
      "gmtCreate": 1646306448519,
      "gmtModified": 1646306448519,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_failure_stats_1d",
      "alias": "应用天级别故障统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"failure\"\ninstance_path = {\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\",\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\"\n}\n\n\ndef get_definitions_group_by_component():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(s_timestamp, e_timestamp):\n    path = instance_path[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"] + \"#\" + result[\"appComponentName\"]\n        ins_key = result[\"appInstanceId\"] + \"#\" + result[\"appComponentInstanceId\"]\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appComponentName\": result[\"appComponentName\"],\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appComponentName\": result[\"appComponentName\"],\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"appComponentInstanceId\": result[\"appComponentInstanceId\"],\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_second_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component()\n    ins_daily_dict = get_instances(start_timestamp, end_timestamp)\n    ins_dict = get_instances(None, None)\n\n    results = []\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[\"defCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[\"instanceCnt\"] = instance[\"cnt\"]\n            result[\"instanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n            result[\"ds\"] = start_ds\n\n            results.append(result)\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 91,
        "type": "model",
        "layer": "dws"
      }
    }, {
      "id": 96,
      "gmtCreate": 1646306448526,
      "gmtModified": 1646306448526,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_health_stats_1d",
      "alias": "应用天级别健康统计(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport requests\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\n\ndef get_definitions_group_by_component(category):\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        key = result[\"appId\"]\n        if key in datas:\n            datas[key][\"cnt\"] += 1\n        else:\n            data = {\n                \"appId\": result[\"appId\"],\n                \"cnt\": 1\n            }\n            datas[key] = data\n\n    return datas\n\n\ndef get_instances(category, s_timestamp, e_timestamp):\n    path = category_path_mapping[category]\n    if s_timestamp is None and e_timestamp is None:\n        url = host[\"health\"] + path\n    else:\n        url = host[\"health\"] + path + \"?sTimestamp=\" + str(s_timestamp) + \"&eTimestamp=\" + str(e_timestamp)\n\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n    datas = {}\n    for result in results:\n        def_key = result[\"appId\"]\n        ins_key = result[\"appInstanceId\"]\n        if def_key in datas:\n            data = datas[def_key]\n            if ins_key in data:\n                data[ins_key][\"cnt\"] += 1\n            else:\n                item = {\n                    \"id\": ins_key,\n                    \"appId\": result[\"appId\"],\n                    \"appInstanceId\": result[\"appInstanceId\"],\n                    \"cnt\": 1\n                }\n                data[ins_key] = item\n        else:\n            item = {\n                \"id\": ins_key,\n                \"appId\": result[\"appId\"],\n                \"appInstanceId\": result[\"appInstanceId\"],\n                \"cnt\": 1\n            }\n            data = {\n                ins_key: item\n            }\n            datas[def_key] = data\n\n    return datas\n\n\ndef get_results_by_category(category, now_day_utc_dt):\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 86400000\n\n    definitions_dict = get_definitions_group_by_component(category)\n    ins_daily_dict = get_instances(category, start_timestamp, end_timestamp)\n    ins_dict = get_instances(category, None, None)\n\n    results = {}\n    for def_key, instance_dict in ins_dict.items():\n        for ins_key, instance in instance_dict.items():\n            result = instance\n            result[category + \"DefCnt\"] = definitions_dict[def_key][\"cnt\"]\n            result[category + \"InstanceCnt\"] = instance[\"cnt\"]\n            result[category + \"InstanceCntDailyAdditions\"] = ins_daily_dict.get(def_key, {}).get(ins_key, {}).get(\"cnt\", 0)\n            result[\"timestamp\"] = start_timestamp\n\n            results[ins_key] = result\n    return results\n\n\ndef get_sla(now_day_utc_dt):\n    end_timestamp = int(now_day_utc_dt.timestamp()) * one_millisecond\n    start_timestamp = end_timestamp - 7 * 86400000\n\n    url = host[\"health\"] + \"/ocenter/getAppSla?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n    r = requests.get(url, headers=headers)\n    results = []\n    if r.status_code == 200:\n        results = r.json().get(\"data\", [])\n\n    return results\n\n\ndef get_results():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    now_day_utc_dt = now_utc_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n    start_timestamp = int(now_day_utc_dt.timestamp()) * one_millisecond\n\n    yesterday_dt = now_utc_dt + datetime.timedelta(days=-1)\n    start_ds = yesterday_dt.strftime(\"%Y%m%d\")\n\n    risk_results = get_results_by_category(\"risk\", now_day_utc_dt)\n    alert_results = get_results_by_category(\"alert\", now_day_utc_dt)\n    incident_results = get_results_by_category(\"incident\", now_day_utc_dt)\n    failure_results = get_results_by_category(\"failure\", now_day_utc_dt)\n\n    sla_results = get_sla(now_day_utc_dt)\n\n    all_app_instance_ids = set(risk_results.keys())\n    all_app_instance_ids.update(set(alert_results.keys()))\n    all_app_instance_ids.update(set(incident_results.keys()))\n    all_app_instance_ids.update(set(failure_results.keys()))\n\n    results = []\n    for app_instance_id in all_app_instance_ids:\n        risk = risk_results.get(app_instance_id, {})\n        alert = alert_results.get(app_instance_id, {})\n        incident = incident_results.get(app_instance_id, {})\n        failure = failure_results.get(app_instance_id, {})\n\n        app_id = \"\"\n        if risk:\n            app_id = risk.get(\"appId\")\n        if alert:\n            app_id = alert.get(\"appId\")\n        if incident:\n            app_id = incident.get(\"appId\")\n        if failure:\n            app_id = failure.get(\"appId\")\n\n        result = {\n            \"id\": app_instance_id,\n            \"appId\": app_id,\n            \"appInstanceId\": app_instance_id,\n            \"timestamp\": start_timestamp,\n            \"ds\": start_ds,\n            \"sla\": sla_results.get(app_instance_id, 1.0),\n            \"riskDefCnt\": risk.get(\"riskDefCnt\", 0),\n            \"alertDefCnt\": alert.get(\"alertDefCnt\", 0),\n            \"incidentDefCnt\": incident.get(\"incidentDefCnt\", 0),\n            \"failureDefCnt\": failure.get(\"failureDefCnt\", 0),\n            \"riskInstanceCnt\": risk.get(\"riskInstanceCnt\", 0),\n            \"alertInstanceCnt\": alert.get(\"alertInstanceCnt\", 0),\n            \"incidentInstanceCnt\": incident.get(\"incidentInstanceCnt\", 0),\n            \"failureInstanceCnt\": failure.get(\"failureInstanceCnt\", 0),\n            \"riskInstanceCntDailyAdditions\": risk.get(\"riskInstanceCntDailyAdditions\", 0),\n            \"alertInstanceCntDailyAdditions\": alert.get(\"alertInstanceCntDailyAdditions\", 0),\n            \"incidentInstanceCntDailyAdditions\": incident.get(\"incidentInstanceCntDailyAdditions\", 0),\n            \"failureInstanceCntDailyAdditions\": failure.get(\"failureInstanceCntDailyAdditions\", 0),\n        }\n        results.append(result)\n\n    return results\n\n\nprint(json.dumps(get_results()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 65,
        "type": "model",
        "layer": "ads"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 92,
  "gmtCreate": 1646306448585,
  "gmtModified": 1646306448585,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_health_definition_collect",
  "alias": "应用健康定义采集作业(内置)",
  "tags": ["app", "health", "definition"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 3 0 * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 97,
      "gmtCreate": 1646306448567,
      "gmtModified": 1646306448567,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_risk_definition",
      "alias": "应用风险定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"risk\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 1,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 98,
      "gmtCreate": 1646306448572,
      "gmtModified": 1646306448572,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_alert_definition",
      "alias": "应用告警定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"alert\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 3,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 99,
      "gmtCreate": 1646306448576,
      "gmtModified": 1646306448576,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_incident_definition",
      "alias": "应用异常定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"incident\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 5,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 100,
      "gmtCreate": 1646306448580,
      "gmtModified": 1646306448580,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_failure_definition",
      "alias": "应用故障定义明细(内置)",
      "execTimeout": 600,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport requests\n\nheaders = {}\n\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory = \"failure\"\n\n\ndef getDefinitions():\n    url = host[\"health\"] + \"/definition/getDefinitionsByCategory?category=\" + category\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n\n    return result\n\n\nprint(json.dumps(getDefinitions()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 7,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 93,
  "gmtCreate": 1646306448662,
  "gmtModified": 1646306448662,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_app_health_instance_collect",
  "alias": "应用健康实例采集作业(内置)",
  "tags": ["app", "health", "instance"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "15 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 101,
      "gmtCreate": 1646306448639,
      "gmtModified": 1646306448639,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_risk_instance",
      "alias": "应用风险实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"risk\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    ds = utc_dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 2,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 102,
      "gmtCreate": 1646306448644,
      "gmtModified": 1646306448644,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_alert_instance",
      "alias": "应用告警实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"alert\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    ds = utc_dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 4,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 103,
      "gmtCreate": 1646306448651,
      "gmtModified": 1646306448651,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_incident_instance",
      "alias": "应用异常实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"incident\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    ds = utc_dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 6,
        "type": "model",
        "layer": "dwd"
      }
    }, {
      "id": 104,
      "gmtCreate": 1646306448656,
      "gmtModified": 1646306448656,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_app_failure_instance",
      "alias": "应用故障实例明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport datetime\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"health\": \"http://prod-health-health.sreworks.svc.cluster.local:80\"\n}\n\ncategory_path_mapping = {\n    \"incident\": \"/incident_instance/getIncidents\",\n    \"failure\": \"/failure_instance/getFailures\",\n    \"risk\": \"/risk_instance/getRisks\",\n    \"alert\": \"/alert_instance/getAlerts\"\n}\n\ncategory = \"failure\"\n\none_second_millisecond = 1000\none_minute_millisecond = 60000\n\n\ndef get_instances():\n    utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    ds = utc_dt.strftime(\"%Y%m%d\")\n\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    path = category_path_mapping[category]\n    url = host[\"health\"] + path + \"?sTimestamp=\" + str(start_timestamp) + \"&eTimestamp=\" + str(end_timestamp)\n\n    r = requests.get(url, headers=headers)\n    result = []\n    if r.status_code == 200:\n        result = r.json().get(\"data\", [])\n        for item in result:\n            item['ds'] = ds\n\n    return result\n\n\nprint(json.dumps(get_instances()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 8,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 94,
  "gmtCreate": 1646306448721,
  "gmtModified": 1646381186593,
  "creator": "",
  "operator": "999999999",
  "appId": "",
  "name": "oem_demoApp_basic_performance_metric_collect",
  "alias": "demoApp基础性能指标采集作业(内置)",
  "tags": ["demoApp", "basic_performance_metric"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "20 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "parallel",
  "scheduleConf": {
    "taskIdList": [{
      "id": 105,
      "gmtCreate": 1646306448699,
      "gmtModified": 1646380398830,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_demoApp_ram_efficiency",
      "alias": "demoApp应用RAM水位(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndemo_app_id = \"sreworks1\"\n\n\ndef get_app_resource_limit(app_id):\n    endpoint = host[\"app\"] + \"/appdev/app/listAll\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n\n    limit = {}\n    if datas:\n        for data in datas:\n            if data[\"appId\"] == app_id:\n                limit = data.get(\"detailDict\", {}).get(\"resource\", {}).get(\"limits\", {})\n    if limit:\n        memory_unit = limit[\"memory\"][-1].upper()\n        memory_number = int(limit[\"memory\"][0:-1])\n        if memory_unit == \"T\":\n            limit[\"memory\"] = memory_number * 1024\n        elif memory_unit == \"M\":\n            limit[\"memory\"] = memory_number / 1024.0\n        else:\n            limit[\"memory\"] = memory_number\n\n    return limit\n\n\ndef _do_get_pod_resource_allocated(endpoint, start_timestamp, end_timestamp, app_id):\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&appId={app_id}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas\n\n\ndef get_pod_resource_allocated(app_id):\n    resource_limit = get_app_resource_limit(app_id)\n    memory_limit = resource_limit.get(\"memory\", 0)\n    cpu_limit = resource_limit.get(\"cpu\", 0)\n\n    now_millisecond = int(time.time()) * one_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    end_timestamp = current_minute_timestamp - one_minute_millisecond\n    start_timestamp = end_timestamp - one_minute_millisecond\n\n    endpoint_cpu_core = host[\"dataset\"] + \"/interface/pod_resource_hours_allocation\"\n    pod_resource_allocation_list = _do_get_pod_resource_allocated(endpoint_cpu_core, start_timestamp, end_timestamp, app_id)\n\n    result = {}\n    for pod_resource_allocation in pod_resource_allocation_list:\n        app_instance_id = pod_resource_allocation[\"appInstanceId\"]\n        key = app_instance_id\n        pod_ram_gb_hours_allocation = 0 if pod_resource_allocation[\"podRamGbHoursAllocation\"] is None else pod_resource_allocation[\"podRamGbHoursAllocation\"]\n        pod_cpu_core_hours_allocation = 0 if pod_resource_allocation[\"podCpuCoreHoursAllocation\"] is None else pod_resource_allocation[\"podCpuCoreHoursAllocation\"]\n        pod_pvc_gb_hours_allocation = 0 if pod_resource_allocation[\"podPVCGbHoursAllocation\"] is None else pod_resource_allocation[\"podPVCGbHoursAllocation\"]\n        pod_cpu_core_hours_usage_avg = 0 if pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"] is None else pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"]\n        pod_ram_gb_hours_usage_avg = 0 if pod_resource_allocation[\"podRamGbHoursUsageAvg\"] is None else pod_resource_allocation[\"podRamGbHoursUsageAvg\"]\n        if key in result:\n            result[key][\"podRamGbAllocation\"] += pod_ram_gb_hours_allocation\n            result[key][\"podCpuCoreAllocation\"] += pod_cpu_core_hours_allocation\n            result[key][\"podPVCGbAllocation\"] += pod_pvc_gb_hours_allocation\n            result[key][\"podCpuCoreUsageAvg\"] += pod_cpu_core_hours_usage_avg\n            result[key][\"podRamGbUsageAvg\"] += pod_ram_gb_hours_usage_avg\n            result[key][\"ramEfficiency\"] = 1.0 if memory_limit == 0 else result[key][\"podRamGbUsageAvg\"] / float(memory_limit)\n            result[key][\"cpuEfficiency\"] = 1.0 if cpu_limit == 0 else result[key][\"podCpuCoreUsageAvg\"] / float(cpu_limit)\n        else:\n            result[key] = {\n                \"appInstanceId\": pod_resource_allocation[\"appInstanceId\"],\n                \"appId\": pod_resource_allocation[\"appId\"],\n                \"appInstanceName\": pod_resource_allocation[\"appInstanceName\"],\n                \"podRamGbAllocation\": pod_ram_gb_hours_allocation,\n                \"podCpuCoreAllocation\": pod_cpu_core_hours_allocation,\n                \"podPVCGbAllocation\": pod_pvc_gb_hours_allocation,\n                \"podCpuCoreUsageAvg\": pod_cpu_core_hours_usage_avg,\n                \"podRamGbUsageAvg\": pod_ram_gb_hours_usage_avg,\n                \"ramEfficiency\": 1.0 if memory_limit == 0 else pod_ram_gb_hours_usage_avg / float(memory_limit),\n                \"cpuEfficiency\": 1.0 if cpu_limit == 0 else pod_cpu_core_hours_usage_avg / float(cpu_limit),\n                \"id\": key + \"_\" + str(start_timestamp),\n                \"timestamp\": start_timestamp\n            }\n\n    metric_datas = []\n    for app_instance_id, item in result.items():\n        metric_data = {\n            \"id\": item[\"id\"],\n            \"timestamp\": item[\"timestamp\"],\n            # \"value\": item[\"cpuEfficiency\"],\n            \"value\": item[\"ramEfficiency\"],\n            \"labels\": {\n                \"app_instance_id\": app_instance_id,\n                \"app_instance_name\": item[\"appInstanceName\"]\n            }\n        }\n        metric_datas.append(metric_data)\n    return metric_datas\n\n\nprint(json.dumps(get_pod_resource_allocated(demo_app_id)))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 108,
        "type": "model",
        "relatedMetricId": 2,
        "layer": "dwd"
      }
    }, {
      "id": 106,
      "gmtCreate": 1646306448704,
      "gmtModified": 1646380484089,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_demoApp_cpu_efficiency",
      "alias": "demoApp应用CPU水位(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\ndemo_app_id = \"sreworks1\"\n\n\ndef get_app_resource_limit(app_id):\n    endpoint = host[\"app\"] + \"/appdev/app/listAll\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n\n    limit = {}\n    if datas:\n        for data in datas:\n            if data[\"appId\"] == app_id:\n                limit = data.get(\"detailDict\", {}).get(\"resource\", {}).get(\"limits\", {})\n    if limit:\n        memory_unit = limit[\"memory\"][-1].upper()\n        memory_number = int(limit[\"memory\"][0:-1])\n        if memory_unit == \"T\":\n            limit[\"memory\"] = memory_number * 1024\n        elif memory_unit == \"M\":\n            limit[\"memory\"] = memory_number / 1024.0\n        else:\n            limit[\"memory\"] = memory_number\n\n    return limit\n\n\ndef _do_get_pod_resource_allocated(endpoint, start_timestamp, end_timestamp, app_id):\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&appId={app_id}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas\n\n\ndef get_pod_resource_allocated(app_id):\n    resource_limit = get_app_resource_limit(app_id)\n    memory_limit = resource_limit.get(\"memory\", 0)\n    cpu_limit = resource_limit.get(\"cpu\", 0)\n\n    now_millisecond = int(time.time()) * one_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    end_timestamp = current_minute_timestamp - one_minute_millisecond\n    start_timestamp = end_timestamp - one_minute_millisecond\n\n    endpoint_cpu_core = host[\"dataset\"] + \"/interface/pod_resource_hours_allocation\"\n    pod_resource_allocation_list = _do_get_pod_resource_allocated(endpoint_cpu_core, start_timestamp, end_timestamp, app_id)\n\n    result = {}\n    for pod_resource_allocation in pod_resource_allocation_list:\n        app_instance_id = pod_resource_allocation[\"appInstanceId\"]\n        key = app_instance_id\n        pod_ram_gb_hours_allocation = 0 if pod_resource_allocation[\"podRamGbHoursAllocation\"] is None else pod_resource_allocation[\"podRamGbHoursAllocation\"]\n        pod_cpu_core_hours_allocation = 0 if pod_resource_allocation[\"podCpuCoreHoursAllocation\"] is None else pod_resource_allocation[\"podCpuCoreHoursAllocation\"]\n        pod_pvc_gb_hours_allocation = 0 if pod_resource_allocation[\"podPVCGbHoursAllocation\"] is None else pod_resource_allocation[\"podPVCGbHoursAllocation\"]\n        pod_cpu_core_hours_usage_avg = 0 if pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"] is None else pod_resource_allocation[\"podCpuCoreHoursUsageAvg\"]\n        pod_ram_gb_hours_usage_avg = 0 if pod_resource_allocation[\"podRamGbHoursUsageAvg\"] is None else pod_resource_allocation[\"podRamGbHoursUsageAvg\"]\n        if key in result:\n            result[key][\"podRamGbAllocation\"] += pod_ram_gb_hours_allocation\n            result[key][\"podCpuCoreAllocation\"] += pod_cpu_core_hours_allocation\n            result[key][\"podPVCGbAllocation\"] += pod_pvc_gb_hours_allocation\n            result[key][\"podCpuCoreUsageAvg\"] += pod_cpu_core_hours_usage_avg\n            result[key][\"podRamGbUsageAvg\"] += pod_ram_gb_hours_usage_avg\n            result[key][\"ramEfficiency\"] = 1.0 if memory_limit == 0 else result[key][\"podRamGbUsageAvg\"] / float(memory_limit)\n            result[key][\"cpuEfficiency\"] = 1.0 if cpu_limit == 0 else result[key][\"podCpuCoreUsageAvg\"] / float(cpu_limit)\n        else:\n            result[key] = {\n                \"appInstanceId\": pod_resource_allocation[\"appInstanceId\"],\n                \"appId\": pod_resource_allocation[\"appId\"],\n                \"appInstanceName\": pod_resource_allocation[\"appInstanceName\"],\n                \"podRamGbAllocation\": pod_ram_gb_hours_allocation,\n                \"podCpuCoreAllocation\": pod_cpu_core_hours_allocation,\n                \"podPVCGbAllocation\": pod_pvc_gb_hours_allocation,\n                \"podCpuCoreUsageAvg\": pod_cpu_core_hours_usage_avg,\n                \"podRamGbUsageAvg\": pod_ram_gb_hours_usage_avg,\n                \"ramEfficiency\": 1.0 if memory_limit == 0 else pod_ram_gb_hours_usage_avg / float(memory_limit),\n                \"cpuEfficiency\": 1.0 if cpu_limit == 0 else pod_cpu_core_hours_usage_avg / float(cpu_limit),\n                \"id\": key + \"_\" + str(start_timestamp),\n                \"timestamp\": start_timestamp\n            }\n\n    metric_datas = []\n    for app_instance_id, item in result.items():\n        metric_data = {\n            \"id\": item[\"id\"],\n            \"timestamp\": item[\"timestamp\"],\n            \"value\": item[\"cpuEfficiency\"],\n            # \"value\": item[\"ramEfficiency\"],\n            \"labels\": {\n                \"app_instance_id\": app_instance_id,\n                \"app_instance_name\": item[\"appInstanceName\"]\n            }\n        }\n        metric_datas.append(metric_data)\n    return metric_datas\n\n\nprint(json.dumps(get_pod_resource_allocated(demo_app_id)))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 108,
        "type": "model",
        "relatedMetricId": 1,
        "layer": "dwd"
      }
    }, {
      "id": 107,
      "gmtCreate": 1646306448712,
      "gmtModified": 1646306448712,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_demoApp_response_time_avg",
      "alias": "demoApp应用平均响应时间(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport time\nimport requests\nfrom gql import gql, Client\nfrom gql.transport.aiohttp import AIOHTTPTransport\n\none_second_millisecond = 1000\none_minutes_millisecond = 60000\nfive_minutes_millisecond = 300000\n\nsw_duration_time_format = \"%Y-%m-%d %H%M\"\nsw_duration_time_gap = one_minutes_millisecond\n\ndemo_app_id = \"sreworks1\"\n\nhost = {\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\",\n    \"skywalking\": \"http://prod-dataops-skywalking-oap.sreworks-dataops.svc.cluster.local:12800/graphql\"\n    # \"skywalking\": \"http://skywalking.c38cca9c474484bdc9873f44f733d8bcd.cn-beijing.alicontainer.com/graphql\"\n}\nheaders = {}\n\n\ndef convert_utc_to_local_dt(str_utc_time):\n    # return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc).astimezone(tz.tzlocal())\n    return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc) \\\n        .astimezone(datetime.timezone(datetime.timedelta(hours=8)))\n\n\ndef get_time_range(ts, delta_ts, forward_gap=0):\n    \"\"\"\n    时间范围\n    :param ts:\n    :param delta_ts:\n    :param forward_gap: 默认前推一个delta\n    :return:\n    \"\"\"\n    ts_integer = int(ts)\n    delta_ts_integer = int(delta_ts)\n\n    end_ts = ts_integer - ts_integer % delta_ts_integer\n    start_ts = end_ts - delta_ts_integer\n\n    delta_forward_ts_integer = delta_ts_integer * forward_gap\n\n    return start_ts - delta_forward_ts_integer, end_ts - delta_forward_ts_integer\n\n\ndef build_graphql():\n    query = gql(\n        \"\"\"\n        query queryData($condition: MetricsCondition!, $duration: Duration!) {\n                readMetricsValues: readMetricsValues(condition: $condition, duration: $duration) {\n                  label\n                  values {\n                    values {\n                      value\n                    }\n                  }\n                }\n              }\n    \"\"\"\n    )\n\n    return query\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = []\n    if datas:\n        for data in datas[\"items\"]:\n            if data[\"appId\"] == demo_app_id:\n                app_instances.append(data)\n    return app_instances\n\n\ndef get_app_avg_rt(app_instance, start_ts, end_ts):\n    start_dt = datetime.datetime.fromtimestamp(start_ts / one_second_millisecond).strftime(sw_duration_time_format)\n    end_dt = datetime.datetime.fromtimestamp(end_ts / one_second_millisecond).strftime(sw_duration_time_format)\n\n    transport = AIOHTTPTransport(url=host[\"skywalking\"])\n    client = Client(transport=transport, fetch_schema_from_transport=True)\n\n    duration = {\n        \"start\": start_dt,\n        \"end\": end_dt,\n        \"step\": \"MINUTE\"\n    }\n    condition = {\n        \"name\": \"service_resp_time\",\n        \"entity\": {\n            \"scope\": \"Service\",\n            \"serviceName\": app_instance[\"appInstanceId\"],\n            \"normal\": True\n        }\n    }\n    params = {\"duration\": duration, \"condition\": condition}\n    resp = client.execute(build_graphql(), variable_values=params)\n    results = resp.get(\"readMetricsValues\", {}).get(\"values\", {}).get(\"values\", [])\n    datas = []\n    for i in range(len(results) - 1):\n        print(results[i])\n        data = {\n            \"value\": results[i].get(\"value\", 0),\n            \"timestamp\": start_ts + i * sw_duration_time_gap,\n            \"labels\": {\n                \"app_instance_id\": app_instance[\"appInstanceId\"],\n                \"app_instance_name\": app_instance[\"appInstanceName\"]\n            }\n        }\n        datas.append(data)\n    return datas\n\n\ndef collect():\n    app_instances = get_app_instances()\n    start_ts, end_ts = get_time_range(time.time() * one_second_millisecond, one_minutes_millisecond)\n\n    metric_datas = []\n    for app_instance in app_instances:\n        datas = get_app_avg_rt(app_instance, start_ts, end_ts)\n        metric_datas.extend(datas)\n    return metric_datas\n\n\nprint(json.dumps(collect()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "true",
        "syncDw": "true",
        "id": 108,
        "type": "model",
        "relatedMetricId": 3,
        "layer": "dwd"
      }
    }, {
      "id": 108,
      "gmtCreate": 1646306448716,
      "gmtModified": 1646306448716,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_demoApp_success_rate",
      "alias": "demoApp应用每分钟调用成功率(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport time\nimport requests\nfrom gql import gql, Client\nfrom gql.transport.aiohttp import AIOHTTPTransport\n\none_second_millisecond = 1000\none_minutes_millisecond = 60000\nfive_minutes_millisecond = 300000\n\nsw_duration_time_format = \"%Y-%m-%d %H%M\"\nsw_duration_time_gap = one_minutes_millisecond\n\ndemo_app_id = \"sreworks1\"\n\nhost = {\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\",\n    \"skywalking\": \"http://prod-dataops-skywalking-oap.sreworks-dataops.svc.cluster.local:12800/graphql\"\n    # \"skywalking\": \"http://skywalking.c38cca9c474484bdc9873f44f733d8bcd.cn-beijing.alicontainer.com/graphql\"\n}\nheaders = {}\n\ndef convert_utc_to_local_dt(str_utc_time):\n    # return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc).astimezone(tz.tzlocal())\n    return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc) \\\n        .astimezone(datetime.timezone(datetime.timedelta(hours=8)))\n\n\ndef get_time_range(ts, delta_ts, forward_gap=0):\n    \"\"\"\n    时间范围\n    :param ts:\n    :param delta_ts:\n    :param forward_gap: 默认前推一个delta\n    :return:\n    \"\"\"\n    ts_integer = int(ts)\n    delta_ts_integer = int(delta_ts)\n\n    end_ts = ts_integer - ts_integer % delta_ts_integer\n    start_ts = end_ts - delta_ts_integer\n\n    delta_forward_ts_integer = delta_ts_integer * forward_gap\n\n    return start_ts - delta_forward_ts_integer, end_ts - delta_forward_ts_integer\n\n\ndef build_graphql():\n    query = gql(\n        \"\"\"\n        query queryData($condition: MetricsCondition!, $duration: Duration!) {\n            readMetricsValue: readMetricsValue(condition: $condition, duration: $duration)\n        }\n    \"\"\"\n    )\n\n    return query\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = []\n    if datas:\n        for data in datas[\"items\"]:\n            if data[\"appId\"] == demo_app_id:\n                app_instances.append(data)\n    return app_instances\n\n\ndef get_app_sla(app_instance, start_ts, end_ts):\n    start_dt = datetime.datetime.fromtimestamp(start_ts / one_second_millisecond).strftime(sw_duration_time_format)\n    end_dt = datetime.datetime.fromtimestamp(end_ts / one_second_millisecond).strftime(sw_duration_time_format)\n\n    transport = AIOHTTPTransport(url=host[\"skywalking\"])\n    client = Client(transport=transport, fetch_schema_from_transport=True)\n\n    duration = {\n        \"start\": start_dt,\n        \"end\": end_dt,\n        \"step\": \"MINUTE\"\n    }\n    condition = {\n        \"name\": \"service_sla\",\n        \"entity\": {\n            \"scope\": \"Service\",\n            \"serviceName\": app_instance[\"appInstanceId\"],\n            \"normal\": True\n        }\n    }\n    params = {\"duration\": duration, \"condition\": condition}\n    resp = client.execute(build_graphql(), variable_values=params)\n    sla = resp.get(\"readMetricsValue\", 10000)\n    data = {\n        \"value\": sla,\n        \"timestamp\": end_ts,\n        \"labels\": {\n            \"app_instance_id\": app_instance[\"appInstanceId\"],\n            \"app_instance_name\": app_instance[\"appInstanceName\"]\n        }\n    }\n    return data\n\n\ndef collect():\n    app_instances = get_app_instances()\n    start_ts, end_ts = get_time_range(time.time() * one_second_millisecond, one_minutes_millisecond)\n\n    metric_datas = []\n    for app_instance in app_instances:\n        datas = get_app_sla(app_instance, start_ts, end_ts)\n        metric_datas.extend(datas)\n    return metric_datas\n\n\nprint(json.dumps(collect()))",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "true",
        "syncDw": "true",
        "id": 108,
        "type": "model",
        "relatedMetricId": 4,
        "layer": "dwd"
      }
    }, {
      "id": 112,
      "gmtCreate": 1646381167983,
      "gmtModified": 1646384492389,
      "creator": "999999999",
      "operator": "999999999",
      "appId": "",
      "name": "oem_demoApp_pvc_allocated",
      "alias": "demoApp应用PVC分配(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport time\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\ndemo_app_id = \"sreworks1\"\n\n\ndef _do_get_pod_resource_allocated(endpoint, start_timestamp, end_timestamp, app_id):\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&appId={app_id}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return datas\n\n\ndef get_pod_resource_allocated(app_id):\n    now_millisecond = int(time.time()) * one_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    end_timestamp = current_minute_timestamp - one_minute_millisecond\n    start_timestamp = end_timestamp - one_minute_millisecond\n\n    endpoint_cpu_core = host[\"dataset\"] + \"/interface/pod_resource_hours_allocation\"\n    pod_resource_allocation_list = _do_get_pod_resource_allocated(endpoint_cpu_core, start_timestamp, end_timestamp, app_id)\n\n    result = {}\n    for pod_resource_allocation in pod_resource_allocation_list:\n        app_instance_id = pod_resource_allocation[\"appInstanceId\"]\n        key = app_instance_id\n        pod_pvc_gb_hours_allocation = 0 if pod_resource_allocation[\"podPVCGbHoursAllocation\"] is None else pod_resource_allocation[\"podPVCGbHoursAllocation\"]\n        if key in result:\n            result[key][\"podPVCGbAllocation\"] += pod_pvc_gb_hours_allocation\n        else:\n            result[key] = {\n                \"appInstanceId\": pod_resource_allocation[\"appInstanceId\"],\n                \"appId\": pod_resource_allocation[\"appId\"],\n                \"appInstanceName\": pod_resource_allocation[\"appInstanceName\"],\n                \"podPVCGbAllocation\": pod_pvc_gb_hours_allocation,\n                \"id\": key + \"_\" + str(start_timestamp),\n                \"timestamp\": start_timestamp\n            }\n\n    metric_datas = []\n    for app_instance_id, item in result.items():\n        metric_data = {\n            \"id\": item[\"id\"],\n            \"timestamp\": item[\"timestamp\"],\n            \"value\": item[\"podPVCGbAllocation\"],\n            \"labels\": {\n                \"app_instance_id\": app_instance_id,\n                \"app_instance_name\": item[\"appInstanceName\"]\n            }\n        }\n        metric_datas.append(metric_data)\n    return metric_datas\n\n\nprint(json.dumps(get_pod_resource_allocated(demo_app_id)))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 108,
        "type": "model",
        "relatedMetricId": 7,
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 95,
  "gmtCreate": 1646306448766,
  "gmtModified": 1646306448766,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_demoApp_pod_event_collect",
  "alias": "demoApp应用POD事件明细采集作业(内置)",
  "tags": ["demoApp", "pod", "event"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "20 0/5 * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 109,
      "gmtCreate": 1646306448757,
      "gmtModified": 1646629526795,
      "creator": "",
      "operator": "999999999",
      "appId": "",
      "name": "oem_demoApp_pod_event",
      "alias": "demoApp应用POD事件明细(内置)",
      "execTimeout": 300,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport json\nimport time\nimport requests\n\nheaders = {}\n\npage_size = 1000\none_millisecond = 1000\nfive_minutes_millisecond = 300000\none_hour_minutes_millisecond = 3600000\n\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\",\n    \"health\": \"http://prod-health-health:80\",\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\ndemo_app_id = \"sreworks1\"\ndemo_app_name = \"demoApp\"\napps = {demo_app_id: demo_app_name}\n\n\ndef convert_utc_to_local_dt(gmt_ts):\n    print(datetime.datetime.fromtimestamp(gmt_ts, tzinfo=datetime.timezone.utc))\n\n\ndef get_time_range(ts, delta_ts, forward_gap=0):\n    \"\"\"\n    时间范围\n    :param ts:\n    :param delta_ts:\n    :param forward_gap: 默认前推一个delta\n    :return:\n    \"\"\"\n    ts_integer = int(ts)\n    delta_ts_integer = int(delta_ts)\n\n    end_ts = ts_integer - ts_integer % delta_ts_integer\n    start_ts = end_ts - delta_ts_integer\n\n    delta_forward_ts_integer = delta_ts_integer * forward_gap\n\n    return start_ts - delta_forward_ts_integer, end_ts - delta_forward_ts_integer\n\n\ndef get_pod_events():\n    endpoint = host[\"dataset\"] + \"/interface/pod_event\"\n    start_timestamp, end_timestamp = get_time_range(time.time() * one_millisecond, five_minutes_millisecond)\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n\n    page_num = 1\n    events = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                events.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    return events\n\n\ndef get_app_pods(app_id, app_name):\n    endpoint = host[\"dataset\"] + \"/interface/app_pod\"\n    end_timestamp = int(time.time() * one_millisecond)\n    start_timestamp = end_timestamp - one_hour_minutes_millisecond\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&appId={app_id}&pageSize={page_size}'''\n\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n\n    app_pods = {}\n    for data in datas:\n        key = data[\"namespace\"] + \"#\" + data[\"podName\"]\n        # data['podName'] = data['podName']\n        data['appId'] = app_id\n        data['appName'] = app_name\n        data['appComponentName'] = data['appComponentName']\n        data['appInstanceId'] = data['appInstanceId']\n        data['appComponentInstanceId'] = data['appInstanceId']\n        app_pods[key] = data\n    return app_pods\n\n\n\ndef get_health_event():\n    endpoint = host[\"health\"] + \"/definition/getDefinitions?category=event\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_pod_events = {}\n    if datas:\n        for data in datas:\n            if data[\"type\"] == \"POD事件\":\n                app_id = data[\"appId\"]\n                app_component_name = data.get(\"appComponentName\", app_id)\n                key = app_id + \"#\" + app_component_name\n                if key in app_pod_events:\n                    app_pod_events[key].append(data)\n                else:\n                    app_pod_events[key] = [data]\n    return app_pod_events\n\n\ndef push_event_instance(def_id, event_instances):\n    endpoint = host[\"health\"] + \"/event_instance/pushEvents\"\n    url = f'''{endpoint}?defId={def_id}'''\n\n    r = requests.post(url, headers=headers, json=event_instances)\n    if r.status_code != 200:\n        print(r.json())\n\n\ndef sync():\n    app_pod_events = get_health_event()\n    app_pods = {}\n    for app_component, event in app_pod_events.items():\n        app_id = app_component.split(\"#\")[0]\n        if app_id in apps:\n            app_name = apps[app_id]\n            pods = get_app_pods(app_id, app_name)\n            app_pods.update(pods)\n\n    events = get_pod_events()\n\n    app_component_event_instances = {}\n    if app_pods and events:\n        for event in events:\n            key = event[\"namespace\"] + \"#\" + event[\"podName\"]\n            pod = app_pods.get(key, None)\n            if pod is not None:\n                event[\"occurTs\"] = event[\"gmtOccur\"]\n                event[\"timestamp\"] = int(time.time() * one_millisecond)\n                event['appId'] = pod['appId']\n                event['appName'] = pod['appName']\n                event['appComponentName'] = pod['appComponentName']\n                event['appInstanceId'] = pod['appInstanceId']\n                event['appComponentInstanceId'] = pod['appInstanceId']\n                event['type'] = pod['type']\n                event['content'] = event['message']\n                event['source'] = \"POD事件采集\"\n\n                key = pod['appId'] + \"#\" + pod['appComponentName']\n                if key in app_component_event_instances:\n                    app_component_event_instances[key].append(event)\n                else:\n                    app_component_event_instances[key] = [event]\n\n    results = []\n    for app_component, event_instances in app_component_event_instances.items():\n        event_conf_list = app_pod_events.get(app_component)\n        for event_conf in event_conf_list:\n            push_event_instance(event_conf['id'], event_instances)\n        results.extend(event_instances)\n\n    return results\n\n\nprint(json.dumps(sync()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 39,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 96,
  "gmtCreate": 1646306448804,
  "gmtModified": 1646306448804,
  "creator": "",
  "operator": "",
  "appId": "",
  "name": "oem_demoApp_user_order_failed_cnt_collect",
  "alias": "demApp每分钟用户订单失败数量采集作业(内置)",
  "tags": ["demoApp", "user_order_failed_cnt"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "2 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 110,
      "gmtCreate": 1646306448799,
      "gmtModified": 1646306448799,
      "creator": "",
      "operator": "",
      "appId": "",
      "name": "oem_demoApp_user_order_failed_cnt",
      "alias": "demoApp每分钟用户订单失败数(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport time\nimport requests\nimport random\n\ndemo_app_id = \"sreworks1\"\none_second_millisecond = 1000\n\nheaders = {}\nhost = {\n    \"app\": \"http://prod-app-app.sreworks.svc.cluster.local:80\"\n}\n\n\ndef get_app_instances():\n    endpoint = host[\"app\"] + \"/appcenter/appInstance/allAppInstances?page=1&pageSize=1000000\"\n    r = requests.get(endpoint, headers=headers)\n    datas = r.json().get(\"data\", None)\n    app_instances = []\n    if datas:\n        for data in datas[\"items\"]:\n            if data[\"appId\"] == demo_app_id:\n                app_instances.append(data)\n    return app_instances\n\n\ndef build_metric_data():\n    app_instances = get_app_instances()\n    metric_datas = []\n    for app_instance in app_instances:\n        metric_data = {\n            \"timestamp\": int(time.time() * one_second_millisecond),\n            \"value\": random.randint(0, 8),\n            \"labels\": {\n                \"app_instance_id\": app_instance[\"appInstanceId\"],\n                \"app_instance_name\": app_instance[\"appInstanceName\"],\n                \"app_component_instance_id\": app_instance[\"appInstanceId\"],\n            }\n        }\n        metric_datas.append(metric_data)\n    return metric_datas\n\n\nprint(json.dumps(build_metric_data()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "true",
        "syncDw": "true",
        "id": 108,
        "type": "model",
        "relatedMetricId": 6,
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 97,
  "gmtCreate": 1646378426621,
  "gmtModified": 1646380217559,
  "creator": "999999999",
  "operator": "999999999",
  "appId": "",
  "name": "oem_pod_resource_allocated_collect",
  "alias": "POD资源分配明细采集作业(内置)",
  "tags": ["oem", "pod_resource_allocated"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "0 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 111,
      "gmtCreate": 1646378306262,
      "gmtModified": 1646378306262,
      "creator": "999999999",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_pod_resource_allocated",
      "alias": "POD资源分配明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport datetime\nimport time\nimport json\nimport requests\n\nheaders = {}\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\npage_size = 1000\none_second_millisecond = 1000\none_minute_millisecond = 60000\none_hour_millisecond = 3600000\n\n\ndef convert_utc_to_local_dt(str_utc_time):\n    # return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc).astimezone(tz.tzlocal())\n    return datetime.datetime.strptime(str_utc_time, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=datetime.timezone.utc) \\\n        .astimezone(datetime.timezone(datetime.timedelta(hours=8)))\n\n\ndef _do_get_pod_resource_allocated(endpoint, start_timestamp, end_timestamp):\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}&pageSize={page_size}'''\n    page_num = 1\n    datas = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                datas.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n    results = {}\n    for data in datas:\n        key = data[\"namespace\"] + \"#\" + data[\"podName\"]\n        if key not in results:\n            results[key] = data\n    return results\n\n\ndef get_pod_resource_allocated():\n    now_utc_dt = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)\n    start_ds = now_utc_dt.strftime(\"%Y%m%d\")\n    now_millisecond = int(time.time()) * one_second_millisecond\n    current_minute_timestamp = now_millisecond - now_millisecond % one_minute_millisecond\n    start_timestamp = current_minute_timestamp - one_minute_millisecond\n    end_timestamp = current_minute_timestamp\n\n    endpoint_cpu_core = host[\"dataset\"] + \"/interface/pod_cpu_core_hours_allocation\"\n    pod_cpu_core_allocation = _do_get_pod_resource_allocated(endpoint_cpu_core, start_timestamp, end_timestamp)\n\n    endpoint_ram_gb = host[\"dataset\"] + \"/interface/pod_ram_gb_hours_allocation\"\n    pod_ram_gb_allocation = _do_get_pod_resource_allocated(endpoint_ram_gb, start_timestamp, end_timestamp)\n\n    endpoint_pvc_gb = host[\"dataset\"] + \"/interface/pod_pvc_gb_hours_allocation\"\n    pod_pvc_gb_allocation = _do_get_pod_resource_allocated(endpoint_pvc_gb, start_timestamp, end_timestamp)\n\n    endpoint_cpu_usage = host[\"dataset\"] + \"/interface/pod_cpu_core_hours_usage_avg\"\n    pod_cpu_core_usage_avg = _do_get_pod_resource_allocated(endpoint_cpu_usage, start_timestamp, end_timestamp)\n\n    endpoint_ram_usage = host[\"dataset\"] + \"/interface/pod_ram_gb_hours_usage_avg\"\n    pod_ram_gb_usage_avg = _do_get_pod_resource_allocated(endpoint_ram_usage, start_timestamp, end_timestamp)\n\n    results = []\n    keys1 = set(pod_cpu_core_allocation.keys())\n    keys2 = set(pod_ram_gb_allocation.keys())\n    keys1.update(keys2)\n    for key in keys1:\n        result = pod_cpu_core_allocation.get(key, None)\n        if result is None:\n            result = pod_ram_gb_allocation.get(key, None)\n            result[\"podCpuCoreHoursAllocation\"] = 0\n        else:\n            result[\"podRamGbHoursAllocation\"] = pod_ram_gb_allocation.get(key, {}).get(\"podRamGbHoursAllocation\", 0)\n        result[\"podPVCGbHoursAllocation\"] = pod_pvc_gb_allocation.get(key, {}).get(\"podPVCGbHoursAllocation\", 0)\n        result[\"podCpuCoreHoursUsageAvg\"] = pod_cpu_core_usage_avg.get(key, {}).get(\"podCpuCoreHoursUsageAvg\", 0)\n        result[\"podRamGbHoursUsageAvg\"] = pod_ram_gb_usage_avg.get(key, {}).get(\"podRamGbHoursUsageAvg\", 0)\n        result[\"timestamp\"] = start_timestamp\n        result[\"id\"] = key + \"_\" + str(start_timestamp)\n        result[\"ds\"] = start_ds\n        results.append(result)\n\n    return results\n\n\nprint(json.dumps(get_pod_resource_allocated()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 109,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}, {
  "id": 98,
  "gmtCreate": 1646638195021,
  "gmtModified": 1646638570841,
  "creator": "999999999",
  "operator": "999999999",
  "appId": "",
  "name": "oem_app_pod_status_collect",
  "alias": "应用POD状态明细采集作业",
  "tags": ["oem", "pod_status", "app"],
  "description": null,
  "options": null,
  "triggerType": "cron",
  "triggerConf": {
    "cronExpression": "25 * * * * ? *",
    "enabled": true
  },
  "scheduleType": "serial",
  "scheduleConf": {
    "taskIdList": [{
      "id": 113,
      "gmtCreate": 1646638544601,
      "gmtModified": 1646639742419,
      "creator": "999999999",
      "operator": "999999999",
      "appId": "",
      "name": "oem_app_pod_status",
      "alias": "应用POD状态明细(内置)",
      "execTimeout": 60,
      "execType": "python",
      "execContent": "# coding: utf-8\n\nimport json\nimport time\nimport requests\n\nheaders = {}\n\npage_size = 1000\none_millisecond = 1000\none_minutes_millisecond = 60000\n\nhost = {\n    \"dataset\": \"http://prod-dataops-dataset.sreworks-dataops.svc.cluster.local:80\"\n}\n\n\ndef get_time_range(ts, delta_ts, forward_gap=0):\n    \"\"\"\n    时间范围\n    :param ts:\n    :param delta_ts:\n    :param forward_gap: 默认前推一个delta\n    :return:\n    \"\"\"\n    ts_integer = int(ts)\n    delta_ts_integer = int(delta_ts)\n\n    end_ts = ts_integer - ts_integer % delta_ts_integer\n    start_ts = end_ts - delta_ts_integer\n\n    delta_forward_ts_integer = delta_ts_integer * forward_gap\n\n    return start_ts - delta_forward_ts_integer, end_ts - delta_forward_ts_integer\n\n\ndef get_pod_status():\n    endpoint = host[\"dataset\"] + \"/interface/pod_status\"\n    start_timestamp, end_timestamp = get_time_range(time.time() * one_millisecond, one_minutes_millisecond)\n    basic_url = f'''{endpoint}?sTimestamp={start_timestamp}&eTimestamp={end_timestamp}'''\n\n    page_num = 1\n    pod_status_list = []\n    while True:\n        url = basic_url + \"&pageNum=\" + str(page_num)\n        r = requests.get(url, headers=headers)\n        if r.status_code == 200:\n            ret = r.json().get(\"data\", None)\n            if ret is not None:\n                pod_status_list.extend(ret.get(\"datas\"))\n                _total_num = int(ret.get(\"totalNum\"))\n                _page_size = int(ret.get(\"pageSize\"))\n                _page_num = int(ret.get(\"pageNum\"))\n                if _page_size > _total_num:\n                    break\n                else:\n                    page_num = _page_num + 1\n\n    for pod_status in pod_status_list:\n        pod_status[\"id\"] = pod_status[\"namespace\"] + \"_\" + pod_status[\"podName\"] + \"_\" + str(start_timestamp)\n        pod_status[\"podPhase\"] = pod_status[\"podStatus\"][\"phase\"]\n        pod_status[\"podReady\"] = pod_status[\"podStatus\"][\"ready\"]\n\n    return pod_status_list\n\n\nprint(json.dumps(get_pod_status()))\n",
      "execRetryTimes": 0,
      "execRetryInterval": 0,
      "varConf": {},
      "sceneType": "collect",
      "sceneConf": {
        "isPushQueue": "false",
        "syncDw": "true",
        "id": 118,
        "type": "model",
        "layer": "dwd"
      }
    }]
  },
  "sceneType": "collect",
  "sceneConf": {},
  "varConf": {},
  "notifyConf": null,
  "eventConf": []
}]