---
  # create group and user and set user sudoer without password
  - name: create group
    group:
      name: "{{ hadoop_group }}"
      state: present
  - name: create user
    user:
      name: "{{ hadoop_user }}"
      comment: "hadoop hdfs and yarn"
      group: "{{ hadoop_group }}"
      generate_ssh_key: yes
      ssh_key_bits: 2048
      ssh_key_file: .ssh/id_rsa
      shell: /bin/bash
  - name: Config /etc/sudoers
    lineinfile:
      dest: /etc/sudoers
      state: present
      line: '{{ item }}'
      validate: 'visudo -cf %s'
    with_items:
      - "{{ hadoop_user }} ALL=(ALL) NOPASSWD: ALL"
      - "Defaults: {{ hadoop_user }}  !requiretty"

  # copy hdfs namenode ssh key to datanode
  - name: copy hdfs namenode ssh key to datanode
    fetch:
      src: /home/{{ hadoop_user }}/.ssh/id_rsa.pub
      dest: /tmp/.hdfs.{{ inventory_hostname }}.id_rsa.pub
      flat: yes
      when: inventory_hostname in groups['hadoop-hdfs-namenode']
  - name: ignore main node ssh StrictHostKeyChecking
    copy:
      src: template/ssh_config
      dest: /home/{{ hadoop_user }}/.ssh/config
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      mode: '0644'
    when: inventory_hostname in groups['hadoop-hdfs-namenode']
  - name: send .ssh key file to all nodes
    copy:
      src: /tmp/.hdfs.{{ item }}.id_rsa.pub
      dest: /tmp/.hdfs.{{ item }}.id_rsa.pub
      owner: "{{ hadoop_user }}"
    with_items: "{{ groups['hadoop-hdfs-namenode'] }}"
    when: inventory_hostname in groups['hadoop-hdfs-datanode']
  - name: add main node authorized .ssh key to all nodes
    authorized_key:
      user: "{{ hadoop_user }}"
      state: present
      key: "{{ lookup('file', '/tmp/.hdfs.' + item + '.id_rsa.pub') }}"
    with_items: "{{ groups['hadoop-hdfs-namenode'] }}"

  # copy yarn resourcemanager ssh key to nodemanager
  - name: fetch main node .ssh key
    fetch:
      src: /home/{{ hadoop_user }}/.ssh/id_rsa.pub
      dest: /tmp/.yarn.{{ inventory_hostname }}.id_rsa.pub
      flat: yes
      when: inventory_hostname in groups['hadoop-yarn-resource-manager']
  - name: ignore main node ssh StrictHostKeyChecking
    copy:
      src: template/ssh_config
      dest: /home/{{ hadoop_user }}/.ssh/config
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      mode: '0644'
    when: inventory_hostname in groups['hadoop-yarn-resource-manager']
  - name: send .ssh key file to all nodes
    copy:
      src: /tmp/.yarn.{{ item }}.id_rsa.pub
      dest: /tmp/.yarn.{{ item }}.id_rsa.pub
      owner: "{{ hadoop_user }}"
    with_items: "{{ groups['hadoop-yarn-resource-manager'] }}"
    when: inventory_hostname in groups['hadoop-yarn-node-manager']
  - name: add main node authorized .ssh key to all nodes
    authorized_key:
      user: "{{ hadoop_user }}"
      state: present
      key: "{{ lookup('file', '/tmp/.yarn.' + item + '.id_rsa.pub') }}"
    with_items: "{{ groups['hadoop-yarn-resource-manager'] }}"

  - name: make directories
    file:
      path: "{{ item }}"
      state: directory
      recurse: yes
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      mode: '0755'
    with_items:
      - /opt/logs/yarn
      - "/opt/app/hadoop-{{hadoop_file_version}}"
      - /opt/data/hadoop/name
      - /opt/data/hadoop/data
      - /opt/data/hadoop/log
      - /opt/data/hadoop/journal

  # copy tar and unarchive
  - name: copy hadoop file to host
    copy:
      src: "{{ local_hadoop_gz_path }}"
      dest: "/tmp/{{ hadoop_gz_file_name }}"
      owner: root
      group: root
      mode: '0644'
  - name: delete tmp untar directory
    file:
      path: "/tmp/hadoop-{{hadoop_file_version}}"
      state: absent
  - name: untar hadoop gzip file
    unarchive:
      src: "/tmp/{{ hadoop_gz_file_name }}"
      dest: /tmp
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      remote_src: yes
  - name: copy fiels to destination
    synchronize:
      src: "/tmp/hadoop-{{hadoop_file_version}}/"
      dest: "/opt/app/hadoop-{{hadoop_file_version}}"
      recursive: yes
    delegate_to: "{{ inventory_hostname }}"

  # link to hadoop-2.6.1 and hadoop
  - name: "link to hadoop-{{hadoop_file_version}} for tis code"
    file:
      src: "/opt/app/hadoop-{{hadoop_file_version}}"
      dest: "/opt/app/{{ item }}"
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      state: link
      force: yes
    with_items:
      - hadoop

  # deploy config files
  - name: copy config file
    copy:
      src: 'template/hadoop_profile.sh'
      dest: '/etc/profile.d/hadoop_profile.sh'
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      mode: '0644'
  - name: set hadoop-env.sh and yarn-env.sh
    lineinfile:
      state: present
      dest: /opt/app/hadoop/etc/hadoop/{{ item[0] }}
      line: '{{ item[1] }}'
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      mode: '0644'
      create: yes
    with_nested:
      - [ 'hadoop-env.sh', 'yarn-env.sh' ]
      - [ 'export JAVA_HOME={{java_home}}', 'export HADOOP_HOME=/opt/app/hadoop' ]
  - name: copy template files
    template:
      src: 'template/{{ item }}.j2'
      dest: '/opt/app/hadoop/etc/hadoop/{{ item }}'
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      mode: '0644'
    with_items:
      - slaves
      - core-site.xml
      - hdfs-site.xml
      - mapred-site.xml
      - yarn-site.xml
  - name: init namenode
    file:
      path: /opt/app/hadoop/etc/hadoop/slaves.exclude
      state: touch
      owner: "{{ hadoop_user }}"
      group: "{{ hadoop_group }}"
      mode: '0644'
  - name: check if namenode formatted before
    stat:
      path: "{{ hadoop_namenode_format_file }}"
    register: has_namenode_formatted
  - name: format namenode
    command: ./hdfs namenode -format -force
    become: yes
    become_user: "{{ hadoop_user }}"
    args:
      chdir: /opt/app/hadoop/bin
    when: inventory_hostname in groups['hadoop-hdfs-namenode'] and has_namenode_formatted.stat.exists == False
